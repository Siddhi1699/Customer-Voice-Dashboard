# -*- coding: utf-8 -*-
"""clean_reviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tcKWOz_OseWsWNUpwa7XOvVNS0sCsPxV

# 2. Cleaning dataset
"""

import pandas as pd
import numpy as np
import re
import string
from bs4 import BeautifulSoup
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')

# File path
file_path = "amazon_reviews_books_sample.csv"

# Load dataset
df = pd.read_csv(file_path)

# Preview the first 5 rows
df.head()

"""Cleaning Structured data (numerical/categorical )"""

# Drop duplicates
df = df.drop_duplicates(subset=["review_id"])

# # Handle missing values

# # Drop rows where review_body is missing (no text = useless)
# df = df.dropna(subset=["review_body"])

# # Fill missing numeric values with 0
# for col in ["helpful_votes", "total_votes", "star_rating"]:
#     df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)

# # Fill categorical NaNs with "Unknown"
# df["verified_purchase"] = df["verified_purchase"].fillna("Unknown")
# df["vine"] = df["vine"].fillna("Unknown")

# Normalize categorical values

df["verified_purchase"] = df["verified_purchase"].str.upper().replace({"Y": "Yes", "N": "No"})
df["vine"] = df["vine"].str.upper().replace({"Y": "Yes", "N": "No"})

# Add useful derived columns

# Review length (in words)
df["review_length"] = df["review_body"].apply(lambda x: len(str(x).split()))

# Helpful ratio (votes / total)
df["helpful_ratio"] = np.where(df["total_votes"] > 0, df["helpful_votes"] / df["total_votes"], 0)

# Convert review_date to datetime
df["review_date"] = pd.to_datetime(df["review_date"], errors="coerce")

"""cleaning unstructured text (review headline/body)"""

# Simple text cleaning function
def clean_text(text):
    if not isinstance(text, str):
        return ""
    # Remove HTML tags
    text = BeautifulSoup(text, "html.parser").get_text()
    # Lowercase
    text = text.lower()
    # Remove urls
    text = re.sub(r"http\S+|www.\S+", "", text)
    # Remove punctuation, numbers, special chars
    text = re.sub(r"[^a-z\s]", " ", text)
    # Remove extra whitespace
    text = re.sub(r"\s+", " ", text).strip()
    return text

df["clean_review"] = df["review_body"].apply(clean_text)
df["clean_review_headline"] = df["review_headline"].apply(clean_text)

# remove stopwords from the review
stop_words = set(stopwords.words("english"))
df["clean_review_no_stopwords"] = df["clean_review"].apply(
    lambda x: " ".join([w for w in x.split() if w not in stop_words])
)

# Save processed data
output_file = "clean_reviews.csv"
df.to_csv(output_file, index=False)

print(f" Cleaned dataset saved to {output_file} with {len(df)} rows")